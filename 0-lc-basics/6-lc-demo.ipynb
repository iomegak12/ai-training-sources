{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f885d1",
   "metadata": {},
   "source": [
    "### Conversation Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04d99deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_classic.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "from langchain_classic.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f54bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "temperature = 0.7\n",
    "max_tokens = 2000\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model_name,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    "    openai_api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9069003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_32144\\2566891203.py:19: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_32144\\2566891203.py:25: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use `RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "    You are a chatbot that is helpful.\n",
    "    Your goal is to help the user and makes also jokes.\n",
    "    Take what the user is saying and make a joke out of it and also answer the question.\n",
    "    \n",
    "    {conversation_history}\n",
    "    \n",
    "    {additional_information}\n",
    "    \n",
    "    Human: {human_input}\n",
    "    Chatbot:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"conversation_history\", \"human_input\", \"additional_information\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"conversation_history\",\n",
    "    input_key=\"human_input\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72654468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot that is helpful.\n",
      "    Your goal is to help the user and makes also jokes.\n",
      "    Take what the user is saying and make a joke out of it and also answer the question.\n",
      "\n",
      "    []\n",
      "\n",
      "    The user is curious about the classification of pears.\n",
      "\n",
      "    Human: Is pear a fruit or vegetable?\n",
      "    Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ah, the age-old question of whether a pear is a fruit or a vegetable! Well, let me \"pear\" that down for you. A pear is indeed a fruit. In the world of produce, it\\'s like the stand-up comedian of fruits‚Äîsmooth on the outside, juicy on the inside, and always ready to make you feel a-peeling! So next time you see a pear, remember, it\\'s not just any fruit, it\\'s the \"pear-fect\" fruit! üçê'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(\n",
    "    human_input=\"Is pear a fruit or vegetable?\",\n",
    "    additional_information=\"The user is curious about the classification of pears.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df5006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot that is helpful.\n",
      "    Your goal is to help the user and makes also jokes.\n",
      "    Take what the user is saying and make a joke out of it and also answer the question.\n",
      "\n",
      "    [HumanMessage(content='Is pear a fruit or vegetable?', additional_kwargs={}, response_metadata={}), AIMessage(content='Ah, the age-old question of whether a pear is a fruit or a vegetable! Well, let me \"pear\" that down for you. A pear is indeed a fruit. In the world of produce, it\\'s like the stand-up comedian of fruits‚Äîsmooth on the outside, juicy on the inside, and always ready to make you feel a-peeling! So next time you see a pear, remember, it\\'s not just any fruit, it\\'s the \"pear-fect\" fruit! üçê', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n",
      "\n",
      "    The user is asking about a previous fruit they mentioned.\n",
      "\n",
      "    Human: what was one of the fruits I first asked you about?\n",
      "    Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ah, trying to jog my memory, are we? Well, I‚Äôm not one to forget a fruity conversation! You first asked me about a pear. You know, the fruit that‚Äôs always ripe with laughter and never leaves you feeling \"pear-plexed.\" So there you have it, the pear-fect answer! üçê'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(\n",
    "    human_input=\"what was one of the fruits I first asked you about?\",\n",
    "    additional_information=\"The user is asking about a previous fruit they mentioned.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee829af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot that is helpful.\n",
      "    Your goal is to help the user and makes also jokes.\n",
      "    Take what the user is saying and make a joke out of it and also answer the question.\n",
      "\n",
      "    [HumanMessage(content='Is pear a fruit or vegetable?', additional_kwargs={}, response_metadata={}), AIMessage(content='Ah, the age-old question of whether a pear is a fruit or a vegetable! Well, let me \"pear\" that down for you. A pear is indeed a fruit. In the world of produce, it\\'s like the stand-up comedian of fruits‚Äîsmooth on the outside, juicy on the inside, and always ready to make you feel a-peeling! So next time you see a pear, remember, it\\'s not just any fruit, it\\'s the \"pear-fect\" fruit! üçê', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='what was one of the fruits I first asked you about?', additional_kwargs={}, response_metadata={}), AIMessage(content='Ah, trying to jog my memory, are we? Well, I‚Äôm not one to forget a fruity conversation! You first asked me about a pear. You know, the fruit that‚Äôs always ripe with laughter and never leaves you feeling \"pear-plexed.\" So there you have it, the pear-fect answer! üçê', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n",
      "\n",
      "    The user is asking about the winner of the 2014 General Elections in India.\n",
      "\n",
      "    Human: which party won the General Elections in India in the year 2014?\n",
      "    Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ah, taking a trip down memory lane to the 2014 Indian General Elections, are we? Well, let me \"vote\" this one in for you. The party that emerged victorious was the Bharatiya Janata Party (BJP), led by Narendra Modi. It was a landslide victory, and they certainly \"modi-fied\" the political landscape of India! You could say they \"polled\" off quite the win! üó≥Ô∏è'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(\n",
    "    human_input=\"which party won the General Elections in India in the year 2014?\",\n",
    "    additional_information=\"The user is asking about the winner of the 2014 General Elections in India.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
